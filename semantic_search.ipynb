{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_df = pd.read_csv(\"data/company_desc_translated.csv\", sep=\";\")[[\"company_name\", \"description_en\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>description_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Le Fourgon</td>\n",
       "      <td>Le Fourgon delivers your stored drinks to your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comptoir des Vignes</td>\n",
       "      <td>Comptoir des Vignes is a brand of cellars spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shin Sekai</td>\n",
       "      <td>Welcome to our Trustpilot page! Shin Sekai is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nutri Naturel</td>\n",
       "      <td>Nutri-Naturel.com, the leading online organic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maison Martin - Le Piment Français</td>\n",
       "      <td>Maison Martin - Le Piment Francais is the firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12991</th>\n",
       "      <td>Ljbautoparts</td>\n",
       "      <td>Sale of auto body spare parts online: fender, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12992</th>\n",
       "      <td>Aéroports de Paris</td>\n",
       "      <td>Aeroports de Paris, with its three platforms, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12993</th>\n",
       "      <td>Online SAS</td>\n",
       "      <td>Shared hosting with unlimited traffic, domain ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12994</th>\n",
       "      <td>shopequitation</td>\n",
       "      <td>Online specialist in the sale of horse riding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12995</th>\n",
       "      <td>Odyssee Transfer</td>\n",
       "      <td>Private shuttle company between airports, trai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12996 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             company_name  \\\n",
       "0                              Le Fourgon   \n",
       "1                     Comptoir des Vignes   \n",
       "2                              Shin Sekai   \n",
       "3                           Nutri Naturel   \n",
       "4      Maison Martin - Le Piment Français   \n",
       "...                                   ...   \n",
       "12991                        Ljbautoparts   \n",
       "12992                  Aéroports de Paris   \n",
       "12993                          Online SAS   \n",
       "12994                      shopequitation   \n",
       "12995                    Odyssee Transfer   \n",
       "\n",
       "                                          description_en  \n",
       "0      Le Fourgon delivers your stored drinks to your...  \n",
       "1      Comptoir des Vignes is a brand of cellars spec...  \n",
       "2      Welcome to our Trustpilot page! Shin Sekai is ...  \n",
       "3      Nutri-Naturel.com, the leading online organic ...  \n",
       "4      Maison Martin - Le Piment Francais is the firs...  \n",
       "...                                                  ...  \n",
       "12991  Sale of auto body spare parts online: fender, ...  \n",
       "12992  Aeroports de Paris, with its three platforms, ...  \n",
       "12993  Shared hosting with unlimited traffic, domain ...  \n",
       "12994  Online specialist in the sale of horse riding ...  \n",
       "12995  Private shuttle company between airports, trai...  \n",
       "\n",
       "[12996 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(doc):\n",
    "    # Lemmatizes and removes stopwords\n",
    "    # doc needs to be a spacy Doc object\n",
    "    txt = [token.lemma_ for token in doc if not token.is_stop and len(token.text) > 2]\n",
    "\n",
    "    if len(txt) > 2:\n",
    "        return ' '.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in company_df['description_en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11365, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.DataFrame({'clean': txt})\n",
    "df_clean = df_clean.dropna().drop_duplicates()\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fourgon deliver store drink home order place l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comptoir des vigne brand cellar specialize win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>welcome trustpilot page shin sekai online figu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nutri naturel com lead online organic grocery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maison martin piment francais brand artisanal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12991</th>\n",
       "      <td>sale auto body spare part online fender bumper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12992</th>\n",
       "      <td>aeroport paris platform major connection point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12993</th>\n",
       "      <td>share host unlimited traffic domain dedicated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12994</th>\n",
       "      <td>online specialist sale horse ride equipment sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12995</th>\n",
       "      <td>private shuttle company airport train station ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11365 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   clean\n",
       "0      fourgon deliver store drink home order place l...\n",
       "1      comptoir des vigne brand cellar specialize win...\n",
       "2      welcome trustpilot page shin sekai online figu...\n",
       "3      nutri naturel com lead online organic grocery ...\n",
       "4      maison martin piment francais brand artisanal ...\n",
       "...                                                  ...\n",
       "12991  sale auto body spare part online fender bumper...\n",
       "12992  aeroport paris platform major connection point...\n",
       "12993  share host unlimited traffic domain dedicated ...\n",
       "12994  online specialist sale horse ride equipment sa...\n",
       "12995  private shuttle company airport train station ...\n",
       "\n",
       "[11365 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating term dictionary\n",
    "%time dictionary = corpora.Dictionary(movie_plot)\n",
    "\n",
    "#filter out terms which occurs in less than 4 documents and more than 20% of the documents.\n",
    "#NOTE: Since we have smaller dataset, we will keep this commented for now.\n",
    "\n",
    "#dictionary.filter_extremes(no_below=4, no_above=0.2)\n",
    "\n",
    "#list of few which which can be further removed\n",
    "stoplist = set('hello and if this can would should could tell ask stop come go')\n",
    "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist if stopword in dictionary.token2id]\n",
    "dictionary.filter_tokens(stop_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(desc) for desc in movie_plot]\n",
    "word_frequencies = [[(dictionary[id], frequency) for id, frequency in line] for line in corpus[0:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_tfidf_model = gensim.models.TfidfModel(corpus, id2word=dictionary)\n",
    "movie_lsi_model = gensim.models.LsiModel(movie_tfidf_model[corpus], id2word=dictionary, num_topics=300)\n",
    "\n",
    "#Serialize and Store the corpus locally for easy retrival whenver required.\n",
    "gensim.corpora.MmCorpus.serialize('movie_tfidf_model_mm', movie_tfidf_model[corpus])\n",
    "gensim.corpora.MmCorpus.serialize('movie_lsi_model_mm',movie_lsi_model[movie_tfidf_model[corpus]])\n",
    "\n",
    "#Load the indexed corpus\n",
    "movie_tfidf_corpus = gensim.corpora.MmCorpus('movie_tfidf_model_mm')\n",
    "movie_lsi_corpus = gensim.corpora.MmCorpus('movie_lsi_model_mm')\n",
    "\n",
    "#Load the MatrixSimilarity\n",
    "from gensim.similarities import MatrixSimilarity\n",
    "movie_index = MatrixSimilarity(movie_lsi_corpus, num_features = movie_lsi_corpus.num_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "def search_similar_movies(search_term):\n",
    "\n",
    "    query_bow = dictionary.doc2bow(spacy_tokenizer(search_term))\n",
    "    query_tfidf = movie_tfidf_model[query_bow]\n",
    "    query_lsi = movie_lsi_model[query_tfidf]\n",
    "\n",
    "    movie_index.num_best = 5\n",
    "\n",
    "    movies_list = movie_index[query_lsi]\n",
    "\n",
    "    movies_list.sort(key=itemgetter(1), reverse=True)\n",
    "    movie_names = []\n",
    "\n",
    "    for j, movie in enumerate(movies_list):\n",
    "\n",
    "        movie_names.append (\n",
    "            {\n",
    "                'Relevance': round((movie[1] * 100),2),\n",
    "                'Movie Title': df_movies['title'][movie[0]],\n",
    "                'Movie Plot': df_movies['wiki_plot'][movie[0]]\n",
    "            }\n",
    "\n",
    "        )\n",
    "        if j == (movie_index.num_best-1):\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(movie_names, columns=['Relevance','Movie Title','Movie Plot'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
