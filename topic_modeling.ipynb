{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling of company Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\marya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\marya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "import pickle\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')  \n",
    "nltk.download('omw-1.4')  \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating example documents\n",
    "doc_1 = \"A whopping 96.5 percent of water on Earth is in our oceans, covering 71 percent of the surface of our planet. And at any given time, about 0.001 percent is floating above us in the atmosphere. If all of that water fell as rain at once, the whole planet would get about 1 inch of rain.\"\n",
    "\n",
    "doc_2 = \"One-third of your life is spent sleeping. Sleeping 7-9 hours each night should help your body heal itself, activate the immune system, and give your heart a break. Beyond that--sleep experts are still trying to learn more about what happens once we fall asleep.\"\n",
    "\n",
    "doc_3 = \"A newborn baby is 78 percent water. Adults are 55-60 percent water. Water is involved in just about everything our body does.\"\n",
    "\n",
    "doc_4 = \"While still in high school, a student went 264.4 hours without sleep, for which he won first place in the 10th Annual Great San Diego Science Fair in 1964.\"\n",
    "\n",
    "doc_5 = \"We experience water in all three states: solid ice, liquid water, and gas water vapor.\"\n",
    "\n",
    "# Create corpus\n",
    "corpus = [doc_1, doc_2, doc_3, doc_4, doc_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords, punctuation, and normalize the corpus\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = \"\".join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "clean_corpus = [clean(doc).split() for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['whopping',\n",
       "  '965',\n",
       "  'percent',\n",
       "  'water',\n",
       "  'earth',\n",
       "  'ocean',\n",
       "  'covering',\n",
       "  '71',\n",
       "  'percent',\n",
       "  'surface',\n",
       "  'planet',\n",
       "  'given',\n",
       "  'time',\n",
       "  '0001',\n",
       "  'percent',\n",
       "  'floating',\n",
       "  'u',\n",
       "  'atmosphere',\n",
       "  'water',\n",
       "  'fell',\n",
       "  'rain',\n",
       "  'once',\n",
       "  'whole',\n",
       "  'planet',\n",
       "  'would',\n",
       "  'get',\n",
       "  '1',\n",
       "  'inch',\n",
       "  'rain'],\n",
       " ['onethird',\n",
       "  'life',\n",
       "  'spent',\n",
       "  'sleeping',\n",
       "  'sleeping',\n",
       "  '79',\n",
       "  'hour',\n",
       "  'night',\n",
       "  'help',\n",
       "  'body',\n",
       "  'heal',\n",
       "  'itself',\n",
       "  'activate',\n",
       "  'immune',\n",
       "  'system',\n",
       "  'give',\n",
       "  'heart',\n",
       "  'break',\n",
       "  'beyond',\n",
       "  'thatsleep',\n",
       "  'expert',\n",
       "  'still',\n",
       "  'trying',\n",
       "  'learn',\n",
       "  'happens',\n",
       "  'fall',\n",
       "  'asleep'],\n",
       " ['newborn',\n",
       "  'baby',\n",
       "  '78',\n",
       "  'percent',\n",
       "  'water',\n",
       "  'adult',\n",
       "  '5560',\n",
       "  'percent',\n",
       "  'water',\n",
       "  'water',\n",
       "  'involved',\n",
       "  'everything',\n",
       "  'body',\n",
       "  'doe'],\n",
       " ['still',\n",
       "  'high',\n",
       "  'school',\n",
       "  'student',\n",
       "  'went',\n",
       "  '2644',\n",
       "  'hour',\n",
       "  'without',\n",
       "  'sleep',\n",
       "  'first',\n",
       "  'place',\n",
       "  '10th',\n",
       "  'annual',\n",
       "  'great',\n",
       "  'san',\n",
       "  'diego',\n",
       "  'science',\n",
       "  'fair',\n",
       "  '1964'],\n",
       " ['experience',\n",
       "  'water',\n",
       "  'three',\n",
       "  'state',\n",
       "  'solid',\n",
       "  'ice',\n",
       "  'liquid',\n",
       "  'water',\n",
       "  'gas',\n",
       "  'water',\n",
       "  'vapor']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating document-term matrix \n",
    "dictionary = corpora.Dictionary(clean_corpus)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in clean_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LsiModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.555*\"water\" + 0.489*\"percent\" + 0.239*\"planet\"'), (1, '-0.361*\"sleeping\" + -0.215*\"hour\" + -0.215*\"still\"'), (2, '-0.562*\"water\" + 0.231*\"planet\" + 0.231*\"rain\"')]\n"
     ]
    }
   ],
   "source": [
    "# LSA model\n",
    "lsa = LsiModel(doc_term_matrix, num_topics=3, id2word = dictionary)\n",
    "\n",
    "# LSA model\n",
    "print(lsa.print_topics(num_topics=3, num_words=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.054*\"water\" + 0.051*\"percent\" + 0.025*\"body\"'), (1, '0.074*\"water\" + 0.026*\"percent\" + 0.021*\"three\"'), (2, '0.028*\"sleeping\" + 0.023*\"still\" + 0.023*\"hour\"')]\n"
     ]
    }
   ],
   "source": [
    "# LDA model\n",
    "lda = LdaModel(doc_term_matrix, num_topics=3, id2word = dictionary)\n",
    "\n",
    "# Results\n",
    "print(lda.print_topics(num_topics=3, num_words=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on our Trustpilot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pipes/pipe4\", \"rb\") as fp:   # Unpickling\n",
    "    pipe4 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe5 = []\n",
    "for company in pipe4:\n",
    "    pipe5.append(\" \".join([x for lst in company for x in lst]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'le fourgon delivers stored drinks home order placed lefourgon.com beers juices sodas water milk wines soups spirits co. deliver home free charge chosen niche next visit collect empty bottles return washed producer reuse zerodechet'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comptoir des vignes brand cellars specializing wines champagnes spirits specialty beers teas coffees delicatessens cellars differentiated original modern presentation products also basis advice adapted new trends consumption habits customers comptoir des vignes cellar offers clear warm setting allows discover wines simplicity indulgence highlighting pairings provision recipe cards regular events store organization tasting evenings 50 cellars france mission satisfy consumers whatever needs desires wide range products services good value money also thanks passion wine merchants'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe5[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemma = WordNetLemmatizer()\n",
    "# pipe6 = []\n",
    "# for company in pipe5[:3]:\n",
    "#     print(company)\n",
    "#     print([lemma.lemmatize(word, pos='a') for word in company])\n",
    "#     print([lemma.lemmatize(word) for word in company])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "pipe6 = []\n",
    "for company in pipe5:\n",
    "    # lemm = nltk.pos_tag(nltk.word_tokenize(company))\n",
    "    # print(lemm)\n",
    "    pipe6.append([lemma.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(company)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['le',\n",
       " 'fourgon',\n",
       " 'delivers',\n",
       " 'store',\n",
       " 'drink',\n",
       " 'home',\n",
       " 'order',\n",
       " 'place',\n",
       " 'lefourgon.com',\n",
       " 'beer',\n",
       " 'juice',\n",
       " 'soda',\n",
       " 'water',\n",
       " 'milk',\n",
       " 'wine',\n",
       " 'soup',\n",
       " 'spirit',\n",
       " 'co.',\n",
       " 'deliver',\n",
       " 'home',\n",
       " 'free',\n",
       " 'charge',\n",
       " 'chosen',\n",
       " 'niche',\n",
       " 'next',\n",
       " 'visit',\n",
       " 'collect',\n",
       " 'empty',\n",
       " 'bottle',\n",
       " 'return',\n",
       " 'wash',\n",
       " 'producer',\n",
       " 'reuse',\n",
       " 'zerodechet']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe6[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
