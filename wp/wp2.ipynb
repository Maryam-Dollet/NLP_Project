{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts-of-Speech-Tagging for sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.nltk.org/_modules/nltk/corpus/reader/sentiwordnet.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part-of-speech tagging is the process of converting a sentence, in the form of a list of words,\n",
    "into a list of tuples, where each tuple is of the form (word, tag). The tag is a part-of-speech\n",
    "tag, and signifies whether the word is a noun, adjective, verb, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the taggers are trainable. They use a list of tagged sentences as their training data, such as\n",
    "what you get from the tagged_sents() method of a TaggedCorpusReader class. With these training\n",
    "sentences, the tagger generates an internal model that will tell it how to tag a word. Other taggers\n",
    "use external data sources or match word patterns to choose a tag for a word.\n",
    "\n",
    "\n",
    "All taggers in NLTK are in the nltk.tag package. Many taggers can also be combined into a backoff\n",
    "chain, so that if one tagger cannot tag a word, the next tagger is used, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.corpus import treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'], ['Mr.', 'Vinken', 'is', 'chairman', 'of', 'Elsevier', 'N.V.', ',', 'the', 'Dutch', 'publishing', 'group', '.'], ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treebank.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = treebank.tagged_sents()[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = UnigramTagger(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('board', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('nonexecutive', 'JJ'),\n",
       " ('director', 'NN'),\n",
       " ('Nov.', 'NNP'),\n",
       " ('29', 'CD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(treebank.sents()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\marya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\sentiwordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('sentiwordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentiSynset('decelerate.v.01'),\n",
       " SentiSynset('slow.v.02'),\n",
       " SentiSynset('slow.v.03'),\n",
       " SentiSynset('slow.a.01'),\n",
       " SentiSynset('slow.a.02'),\n",
       " SentiSynset('dense.s.04'),\n",
       " SentiSynset('slow.a.04'),\n",
       " SentiSynset('boring.s.01'),\n",
       " SentiSynset('dull.s.08'),\n",
       " SentiSynset('slowly.r.01'),\n",
       " SentiSynset('behind.r.03')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(swn.senti_synsets('slow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy = swn.senti_synsets('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy0 = list(happy)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.625\n",
      "0.375\n"
     ]
    }
   ],
   "source": [
    "print(happy0.pos_score())\n",
    "print(happy0.neg_score())\n",
    "print(happy0.obj_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read File to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename, dir):\n",
    "    with open(f\"txt_sentoken/{dir}/{filename}\", \"r\") as f:\n",
    "        article = f.readlines()\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"cv001_19502.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = read_file(filename, 'neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we don't know why the crew was really out in the middle of nowhere , we don't know the origin of what took over the ship ( just that a big pink flashy thing hit the mir ) , and , of course , we don't know why donald sutherland is stumbling around drunkenly throughout . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'know',\n",
       " 'why',\n",
       " 'the',\n",
       " 'crew',\n",
       " 'was',\n",
       " 'really',\n",
       " 'out',\n",
       " 'in',\n",
       " 'the',\n",
       " 'middle',\n",
       " 'of',\n",
       " 'nowhere',\n",
       " ',',\n",
       " 'we',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'know',\n",
       " 'the',\n",
       " 'origin',\n",
       " 'of',\n",
       " 'what',\n",
       " 'took',\n",
       " 'over',\n",
       " 'the',\n",
       " 'ship',\n",
       " '(',\n",
       " 'just',\n",
       " 'that',\n",
       " 'a',\n",
       " 'big',\n",
       " 'pink',\n",
       " 'flashy',\n",
       " 'thing',\n",
       " 'hit',\n",
       " 'the',\n",
       " 'mir',\n",
       " ')',\n",
       " ',',\n",
       " 'and',\n",
       " ',',\n",
       " 'of',\n",
       " 'course',\n",
       " ',',\n",
       " 'we',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'know',\n",
       " 'why',\n",
       " 'donald',\n",
       " 'sutherland',\n",
       " 'is',\n",
       " 'stumbling',\n",
       " 'around',\n",
       " 'drunkenly',\n",
       " 'throughout',\n",
       " '.']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokenized = nltk.word_tokenize(text[5])\n",
    "text_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_tokenized = nltk.word_tokenize(text[2])\n",
    "# text_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replacers import RegexpReplacer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacer = RegexpReplacer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = nltk.word_tokenize(replacer.replace(text[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classer les mots avec le Tagger, puis les filtrer selon le tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('we', 'PRP'),\n",
       " ('do', 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('know', 'VB'),\n",
       " ('why', 'WRB'),\n",
       " ('the', 'DT'),\n",
       " ('crew', None),\n",
       " ('was', 'VBD'),\n",
       " ('really', 'RB'),\n",
       " ('out', 'RP'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('middle', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('nowhere', 'RB'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('do', 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('know', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('origin', None),\n",
       " ('of', 'IN'),\n",
       " ('what', 'WP'),\n",
       " ('took', 'VBD'),\n",
       " ('over', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('ship', None),\n",
       " ('(', None),\n",
       " ('just', 'RB'),\n",
       " ('that', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('big', 'JJ'),\n",
       " ('pink', None),\n",
       " ('flashy', 'JJ'),\n",
       " ('thing', 'NN'),\n",
       " ('hit', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('mir', None),\n",
       " (')', None),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " (',', ','),\n",
       " ('of', 'IN'),\n",
       " ('course', 'NN'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('do', 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('know', 'VB'),\n",
       " ('why', 'WRB'),\n",
       " ('donald', None),\n",
       " ('sutherland', None),\n",
       " ('is', 'VBZ'),\n",
       " ('stumbling', None),\n",
       " ('around', 'IN'),\n",
       " ('drunkenly', None),\n",
       " ('throughout', 'IN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_text = tagger.tag(tokenized_text)\n",
    "tagged_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tag(token):\n",
    "    if token[1] == \"RB\" or token[1] == \"RBR\" or token[1] == \"RBS\" or token[1] == \"\":\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_text = filter(filter_tag, tagged_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tokens = [x[0] for x in list(filter(filter_tag, tagged_text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not', 'really', 'nowhere', 'not', 'just', 'not']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utiliser SentiWordNet pour voir le score de négativité, positivité et objectivité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = swn.senti_synsets('damn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structure de la donnée qui va être prise en paramètre pour faire l'analyse sentimentale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liste de listes qui contienent les phrases tokenisées filtrés selon le tag le modèle fera un average et prendra le meilleur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_score(tuple_list):\n",
    "   \n",
    "    _, pos, neg, _  = zip(*tuple_list)\n",
    "    \n",
    "    return f\"positive : {sum(pos)}, negative : {sum(neg)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(filename):\n",
    "    text = read_file(filename, 'neg')\n",
    "    tokens = []\n",
    "    for sentence in text:\n",
    "        tokenized_text = nltk.word_tokenize(replacer.replace(sentence))\n",
    "        tagged_text = tagger.tag(tokenized_text)\n",
    "\n",
    "        filtered_tokens = [x[0] for x in list(filter(filter_tag, tagged_text))]    \n",
    "\n",
    "        if len(filtered_tokens) != 0:\n",
    "            for token in filtered_tokens:\n",
    "                tokens.append(token)\n",
    "\n",
    "        # print(filtered_tokens)\n",
    "    \n",
    "    print(tokens)\n",
    "\n",
    "    token_score = []\n",
    "    for token in tokens:\n",
    "        happy = swn.senti_synsets(token)\n",
    "        happy0 = list(happy)[0]\n",
    "        # print(token)\n",
    "        # print(f\"pos : {happy0.pos_score()}, neg : {happy0.neg_score()}, obj : {happy0.obj_score()}\")\n",
    "        token_score.append((token, happy0.pos_score(), happy0.neg_score(), happy0.obj_score()))\n",
    "        # print(happy0.pos_score())\n",
    "        # print(happy0.neg_score())\n",
    "        # print(happy0.obj_score())\n",
    "    \n",
    "    print(token_score)\n",
    "    score = calculate_total_score(token_score)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['damn', 'back', 'here', 'still', 'very', 'not', 'really', 'nowhere', 'not', 'just', 'not', 'here', 'just', 'even', 'well', 'here', 'so', 'really', 'here', 'pretty', 'much']\n",
      "[('damn', 0.125, 0.125, 0.75), ('back', 0.0, 0.0, 1.0), ('here', 0.0, 0.0, 1.0), ('still', 0.0, 0.0, 1.0), ('very', 0.5, 0.0, 0.5), ('not', 0.0, 0.625, 0.375), ('really', 0.625, 0.0, 0.375), ('nowhere', 0.0, 0.25, 0.75), ('not', 0.0, 0.625, 0.375), ('just', 0.625, 0.0, 0.375), ('not', 0.0, 0.625, 0.375), ('here', 0.0, 0.0, 1.0), ('just', 0.625, 0.0, 0.375), ('even', 0.0, 0.0, 1.0), ('well', 0.0, 0.0, 1.0), ('here', 0.0, 0.0, 1.0), ('so', 0.0, 0.0, 1.0), ('really', 0.625, 0.0, 0.375), ('here', 0.0, 0.0, 1.0), ('pretty', 0.875, 0.125, 0.0), ('much', 0.125, 0.125, 0.75)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive : 4.125, negative : 2.5'"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
